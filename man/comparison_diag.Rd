% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/diagnostics.R
\name{comparison_diag}
\alias{comparison_diag}
\title{Emulator Comparison Diagnostic}
\usage{
comparison_diag(
  emulator,
  targets = NULL,
  validation = NULL,
  sd = 3,
  plt = T,
  ...
)
}
\arguments{
\item{emulator}{An \code{\link{Emulator}} object.}

\item{targets}{The output targets (to check the relevance of failed points).}

\item{validation}{The validation data.frame containing all inputs and outputs.}

\item{sd}{The number of allowed standard deviations (default 3).}

\item{plt}{Should the plot be produced?}

\item{...}{Dummy parameters for compatibility with the diagnostic wrapper.}
}
\value{
A data.frame of points that fail the diagnostic.
}
\description{
Produces a comparison diagnostic of emulator and simulator prediction.
}
\details{
The emulator output \code{E[f(x)]} is plotted against the simulator output \code{f(x)},
for points in a validation set. Error bars are determined by the emulator standard
deviation \code{sqrt(Var[f(x)])}. Points whose emulator expectation bound does not
contain the actual simulator output are deemed to fail this diagnostic.

If \code{plt = TRUE}, then the equivalent plot is provided. As with
\code{\link{standard_errors}}, if a target is provided to the diagnostic, then points
whose emulator bound does not encompass the simulator result but lie far from the
desired output are discounted.

If a validation dataset is not provided, then cross-validation is performed using the
training set. By default, leave-one-out cross-validation is used; the parameter \code{k}
can be provided as an optional argument to this function to perform k-fold cross validation
(where k must be a multiple of the dataset size).
}
\examples{
comparison_diag(sample_emulators$ems$nS, sample_emulators$targets, GillespieValidation)
## An empty data.frame.
comparison_diag(sample_emulators$ems$nS, sample_emulators$targets, GillespieValidation,
 sd = 0.5)
## A data.frame containing one point.
}
